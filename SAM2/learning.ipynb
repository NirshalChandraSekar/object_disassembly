{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2 # for images\n",
    "from sam2.build_sam import build_sam2_video_predictor # for videos\n",
    "\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(3)\n",
    "\n",
    "# def show_mask(mask, ax, random_color=False, borders = True):\n",
    "#     if random_color:\n",
    "#         color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "#     else:\n",
    "#         color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "#     h, w = mask.shape[-2:]\n",
    "#     mask = mask.astype(np.uint8)\n",
    "#     mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#     if borders:\n",
    "#         import cv2\n",
    "#         contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "#         # Try to smooth contours\n",
    "#         contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "#         mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "#     ax.imshow(mask_image)\n",
    "\n",
    "# def show_points(coords, labels, ax, marker_size=375):\n",
    "#     pos_points = coords[labels==1]\n",
    "#     neg_points = coords[labels==0]\n",
    "#     ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "#     ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "# def show_box(box, ax):\n",
    "#     x0, y0 = box[0], box[1]\n",
    "#     w, h = box[2] - box[0], box[3] - box[1]\n",
    "#     ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "# def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "#     for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "#         plt.figure(figsize=(10, 10))\n",
    "#         plt.imshow(image)\n",
    "#         show_mask(mask, plt.gca(), borders=borders)\n",
    "#         if point_coords is not None:\n",
    "#             assert input_labels is not None\n",
    "#             show_points(point_coords, input_labels, plt.gca())\n",
    "#         if box_coords is not None:\n",
    "#             # boxes\n",
    "#             show_box(box_coords, plt.gca())\n",
    "#         if len(scores) > 1:\n",
    "#             plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "#         plt.axis('off')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"/home/niru/Downloads/Cat03.jpg\")\n",
    "# # cv2.imshow(\"frame\", image)\n",
    "# cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "# image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plt.figure(figsize=(3,3))\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = \"segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "# model_cfg = \"sam2_hiera_l.yaml\"\n",
    "# predictor = SAM2AutomaticMaskGenerator(build_sam2(model_cfg, checkpoint, device=device, apply_postprocessing=False))\n",
    "\n",
    "# masks = predictor.generate(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import supervision as sv\n",
    "\n",
    "# mask_annotator = sv.MaskAnnotator()\n",
    "# detections = sv.Detections.from_sam(masks)\n",
    "# detections.class_id = [i for i in range(len(detections))]\n",
    "# annotated_image = mask_annotator.annotate(image, detections)\n",
    "\n",
    "# sv.plot_image(image=annotated_image, size=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"segment-anything-2/checkpoints/sam2_hiera_small.pt\"\n",
    "config = \"sam2_hiera_s.yaml\"\n",
    "model = build_sam2_video_predictor(config, checkpoint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "frames_generator = sv.get_video_frames_generator(\"input_video.mp4\")\n",
    "sink = sv.ImageSink(\n",
    "    target_dir_path=\"video-frames\",\n",
    "    image_name_pattern=\"{:05d}.jpeg\")\n",
    "\n",
    "with sink:\n",
    "    for frame in frames_generator:\n",
    "        sink.save_image(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_state = model.init_state(\"video-frames\")\n",
    "model.reset_state(inference_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting points in first frame (will be automated later)\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img, (x, y), 3, (0, 0, 255), -1)\n",
    "        points.append(np.array([x, y]))\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "points = []\n",
    "img = cv2.imread('/home/niru/codes/disassembly/SAM2/video-frames/00000.jpeg') # Replace 'your_image.jpg' with your image path\n",
    "cv2.imshow('image', img)\n",
    "cv2.setMouseCallback('image', click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "points = np.array(points)\n",
    "print(\"Selected Points:\", points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {}\n",
    "\n",
    "labels = np.array([1])\n",
    "frame_idx = 0\n",
    "tracker_id_1 = 1\n",
    "\n",
    "prompts[tracker_id_1] = points[0], labels\n",
    "\n",
    "_, object_ids, mask_logits = model.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=frame_idx,\n",
    "    obj_id=tracker_id_1,\n",
    "    points=[points[0]],\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "tracker_id_2 = 2\n",
    "prompts[tracker_id_2] = points[1], labels\n",
    "\n",
    "_, object_ids, mask_logits = model.add_new_points_or_box(\n",
    "    inference_state=inference_state,\n",
    "    frame_idx=frame_idx,\n",
    "    obj_id=tracker_id_2,\n",
    "    points=[points[1]],\n",
    "    labels=labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#FF1493', '#00BFFF', '#FF6347', '#FFD700']\n",
    "mask_annotator = sv.MaskAnnotator(\n",
    "    color=sv.ColorPalette.from_hex(colors),\n",
    "    color_lookup=sv.ColorLookup.TRACK)\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(\"/home/niru/Downloads/IMG_0066-ezgif.com-video-to-mp4-converter.mp4\")\n",
    "frames_paths = sorted(sv.list_files_with_extensions(\n",
    "    directory=\"/home/niru/codes/disassembly/SAM2/video-frames\", \n",
    "    extensions=[\"jpeg\"]))\n",
    "\n",
    "\n",
    "with sv.VideoSink(\"final_output.mp4\", video_info=video_info) as sink:\n",
    "    for frame_idx, object_ids, mask_logits in model.propagate_in_video(inference_state):\n",
    "        frame = cv2.imread(frames_paths[frame_idx])\n",
    "        masks = (mask_logits > 0.0).cpu().numpy()\n",
    "        N, X, H, W = masks.shape\n",
    "        masks = masks.reshape(N * X, H, W)\n",
    "        detections = sv.Detections(\n",
    "            xyxy=sv.mask_to_xyxy(masks=masks),\n",
    "            mask=masks,\n",
    "            tracker_id=np.array(object_ids)\n",
    "        )\n",
    "        frame = mask_annotator.annotate(frame, detections)\n",
    "        sink.write_frame(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
